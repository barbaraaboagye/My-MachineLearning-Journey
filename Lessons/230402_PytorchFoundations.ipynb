{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "886467ac-de7e-46bc-a55e-6fd21277147b",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <h1> My Machine Learning Journey</h1>\n",
    "Civil Engineer · Researcher Youtuber · Machine Learning Engineer (The Goal)\n",
    "    <br>\n",
    "    Sharing and documenting my progress and journey as I learn machine learning\n",
    "     <br>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "<div align=\"center\">\n",
    "    <a target=\"_blank\" href=\"https://github.com/barbaraaboagye/My-MachineLearning-Journey\"><img src=\"https://img.shields.io/github/last-commit/barbaraaboagye/My-MachineLearning-Journey\"></a>&nbsp;\n",
    "      <a target=\"_blank\" href=\"https://www.youtube.com/channel/UCEYKFq7ZEg81GYxpzNqYZ4)\"><img src=\"https://img.shields.io/youtube/channel/subscribers/UCEYKFq7ZEg81GYxpzNqYZ4Q?style=social\"></a>&nbsp;\n",
    "    <a target=\"_blank\" href=\"https://fr.linkedin.com/in/barbara-aboagye-233ba8133\"><img src=\"https://img.shields.io/badge/style--5eba00.svg?label=LinkedIn&logo=linkedin&style=social\"></a>&nbsp;\n",
    "    <a target=\"_blank\" href=\"https://twitter.com/awesome_ama\"><img src=\"https://img.shields.io/twitter/follow/awesome_ama?style=social\"></a>\n",
    "    <br>\n",
    "</div>\n",
    "\n",
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45b714aa-02f9-45ac-b2bf-e83b34b0c093",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# PyTorch Foundation - Day x of x\n",
    "\n",
    "Hours completed : 1hr <br>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "39e4c6e7-9871-4211-8c4e-94bc180dc5f4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Resources used : \n",
    "\n",
    "- [Foundation- PyTorch](https://madewithml.com/courses/foundations/pytorch/)\n",
    "<br>\n",
    "\n",
    "Handwritten notes can be found [here][def]\n",
    "\n",
    "[def]: https://github.com/barbaraaboagye/My-MachineLearning-Journey/blob/f19bcd442db121a37f2c1a261f97796169860bc2/Handwritten%20notes/230402_PytorchFoundations.pdf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "409dd568",
   "metadata": {},
   "source": [
    "### Set up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d27bb2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33186f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "684edb2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff0a0216b90>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set seed for reproducibility\n",
    "\n",
    "np.random.seed(seed=SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0866f3",
   "metadata": {},
   "source": [
    "### Basics \n",
    "\n",
    "We'll first cover some basics with PyTorch such as creating tensors and converting from common data structures (lists, arrays, etc.) to tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e67177f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "Size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[ 0.0461,  0.4024, -1.0115],\n",
      "        [ 0.2167, -0.6123,  0.5036]])\n"
     ]
    }
   ],
   "source": [
    "# Creating a random tensor\n",
    "\n",
    "x = torch.randn(2,3) # normal distribution (rand(2,3) -> uniform distribution)\n",
    "print (f\"Type: {x.type()}\")\n",
    "print (f\"Size: {x.shape}\")\n",
    "print (f\"Values: \\n{x}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32c688ed",
   "metadata": {},
   "source": [
    "This code creates a tensor `x` of size `(2,3)` filled with random values from a normal distribution with mean 0 and standard deviation 1 using PyTorch.\n",
    "\n",
    "The tensor `x` has 2 rows and 3 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5fcc362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "#Zeros and Ones tensor\n",
    "\n",
    "x = torch.zeros(2, 3)\n",
    "print(x)\n",
    "x = torch.ones(2,3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac951d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([1, 2, 3], [4, 5, 6])\n",
      "(2, 3)\n",
      "Type: 2\n",
      "Size: torch.Size([2, 3])\n",
      "x:\n",
      " tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "Size: torch.Size([2, 3])\n",
      "x:\n",
      " tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# List to Tensor\n",
    "\n",
    "x = [1,2,3], [4,5,6 ] # normal list\n",
    "print (x)\n",
    "print(np.shape(x))\n",
    "print(f\"Type: {np.ndim(x)}\")\n",
    "y = torch.Tensor([[1,2,3], [4,5,6 ]])\n",
    "print (f\"Size: {y.shape}\")\n",
    "print(f\"x:\\n {y}\")\n",
    "z = torch.Tensor(x)\n",
    "print (f\"Size: {z.shape}\")\n",
    "print(f\"x:\\n {z}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bad90e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: torch.Size([2, 3])\n",
      "x:\n",
      " tensor([[0.1915, 0.6221, 0.4377],\n",
      "        [0.7854, 0.7800, 0.2726]])\n"
     ]
    }
   ],
   "source": [
    "## NumPy array to Tensor\n",
    "\n",
    "x = torch.Tensor(np.random.rand(2,3))\n",
    "print (f\"Size: {x.shape}\")\n",
    "print(f\"x:\\n {x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2f9f36da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: torch.FloatTensor\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "Type: torch.LongTensor\n",
      "tensor([[0, 0, 0, 0],\n",
      "        [0, 0, 0, 0],\n",
      "        [0, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# Changing tensor type \n",
    "x = torch.Tensor(3,4)\n",
    "print(f\"Type: {x.type()}\")\n",
    "print(x)\n",
    "x = x.long()\n",
    "print(f\"Type: {x.type()}\")\n",
    "print(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "51f767dd",
   "metadata": {},
   "source": [
    "### Long tensor \n",
    "\n",
    "In programming, we often work with numbers, like 1, 2, 3, etc. However, sometimes we need to work with really large numbers that are too big to be represented using the normal integer data type.\n",
    "\n",
    "For example, imagine you have a dataset with billions of entries, and you need to index into it using unique identifiers that are assigned to each entry. In this case, you would need a data type that can represent really large integer values, and that's where LongTensor comes in.\n",
    "\n",
    "In PyTorch, a LongTensor is a special type of data structure that can hold large integer values ranging from -9223372036854775808 to 9223372036854775807. You can think of it like a container that can store really big numbers.\n",
    "\n",
    "You can create a LongTensor by either explicitly converting an existing tensor of a different data type using the .long() method or by directly initializing it using the torch.LongTensor() constructor. Once you have a LongTensor, you can use it for various mathematical operations, just like any other tensor in PyTorch."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3d46265",
   "metadata": {},
   "source": [
    "#### Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3fc722ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: torch.Size([2, 3])\n",
      "Values: \n",
      "tensor([[ 0.0761, -0.6775, -0.3988],\n",
      "        [ 3.0633, -0.1589,  0.3514]])\n"
     ]
    }
   ],
   "source": [
    "# Addition\n",
    "\n",
    "x = torch.randn(2,3)\n",
    "y = torch.randn(2,3)\n",
    "z = x + y\n",
    "print(f\"Size: {z.shape}\")\n",
    "print(f\"Values: \\n{z}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "239f3a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size : torch.Size([2, 2])\n",
      "Values : \n",
      " tensor([[ 1.0796, -0.0759],\n",
      "        [ 1.2746, -0.5134]])\n"
     ]
    }
   ],
   "source": [
    "## Dot product\n",
    "\n",
    "x = torch.randn(2,3)\n",
    "y = torch.randn(3,2)\n",
    "z = torch.mm(x,y)\n",
    "print(f\"Size : {z.shape}\")\n",
    "print(f\"Values : \\n {z}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe74b735",
   "metadata": {},
   "source": [
    "The `torch.mm()` function is used to perform matrix multiplication between two tensors of size `(m,n)` and `(n,p)`, resulting in a tensor of size `(m,p)`. In other words, it multiplies each element of each row of the first tensor with each element of each column of the second tensor, and then sums the products to get the corresponding element of the resulting tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ad6233c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size : torch.Size([2, 3])\n",
      "Values : \n",
      "tensor([[ 0.8042, -0.1383,  0.3196],\n",
      "        [-1.0187, -1.3147,  2.5228]])\n",
      "Size: torch.Size([3, 2])\n",
      "Values: \n",
      "tensor([[ 0.8042, -1.0187],\n",
      "        [-0.1383, -1.3147],\n",
      "        [ 0.3196,  2.5228]])\n"
     ]
    }
   ],
   "source": [
    "# Transpose\n",
    "\n",
    "x = torch.randn(2,3)\n",
    "print(f\"Size : {x.shape}\")\n",
    "print (f\"Values : \\n{x}\")\n",
    "y = torch.t(x)\n",
    "print(f\"Size: {y.shape}\")\n",
    "print(f\"Values: \\n{y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8881c953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values x:\n",
      " tensor([[ 0.4501,  0.2709, -0.8087],\n",
      "        [-0.0217, -1.0413,  0.0702]])\n",
      "Size: torch.Size([3, 2])\n",
      "Values z:\n",
      "tensor([[ 0.4501,  0.2709],\n",
      "        [-0.8087, -0.0217],\n",
      "        [-1.0413,  0.0702]])\n"
     ]
    }
   ],
   "source": [
    "## Reshape \n",
    "x = torch.randn(2,3)\n",
    "print(f\"Values x:\\n {x}\")\n",
    "z = x.view(3,2)\n",
    "print(f\"Size: {z.shape}\")\n",
    "print (f\"Values z:\\n{z}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e544d6b",
   "metadata": {},
   "source": [
    "This code reshapes the tensor `x` using the `.view()` method in PyTorch and assigns the resulting tensor to `z`.\n",
    "\n",
    "The `.view()` method in PyTorch is used to reshape a tensor to a new shape while maintaining the total number of elements in the tensor. In this case, the tensor `x` has dimensions `(2,3)` and a total of 6 elements.\n",
    "\n",
    "The `.view(3, 2)` method is used to reshape `x` into a tensor with dimensions `(3,2)` which also has a total of 6 elements. The resulting tensor `z` will have 3 rows and 2 columns.\n",
    "\n",
    "Note that when reshaping a tensor, the order of the elements in memory is preserved. In other words, the elements are simply rearranged to form the new shape without any change in their values. If the new shape does not have the same number of elements as the original tensor, a runtime error will be raised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f205057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: torch.Size([2, 3, 4])\n",
      "x: \n",
      "tensor([[[ 1,  1,  1,  1],\n",
      "         [ 2,  2,  2,  2],\n",
      "         [ 3,  3,  3,  3]],\n",
      "\n",
      "        [[10, 10, 10, 10],\n",
      "         [20, 20, 20, 20],\n",
      "         [30, 30, 30, 30]]])\n",
      "\n",
      "\n",
      "Size: torch.Size([3, 8])\n",
      "a: \n",
      "tensor([[ 1,  1,  1,  1,  2,  2,  2,  2],\n",
      "        [ 3,  3,  3,  3, 10, 10, 10, 10],\n",
      "        [20, 20, 20, 20, 30, 30, 30, 30]])\n",
      "\n",
      "\n",
      "Size: torch.Size([3, 2, 4])\n",
      "b: \n",
      "tensor([[[ 1,  1,  1,  1],\n",
      "         [10, 10, 10, 10]],\n",
      "\n",
      "        [[ 2,  2,  2,  2],\n",
      "         [20, 20, 20, 20]],\n",
      "\n",
      "        [[ 3,  3,  3,  3],\n",
      "         [30, 30, 30, 30]]])\n",
      "\n",
      "\n",
      "Size: torch.Size([3, 8])\n",
      "c: \n",
      "tensor([[ 1,  1,  1,  1, 10, 10, 10, 10],\n",
      "        [ 2,  2,  2,  2, 20, 20, 20, 20],\n",
      "        [ 3,  3,  3,  3, 30, 30, 30, 30]])\n"
     ]
    }
   ],
   "source": [
    "# Dangers of reshaping (unintended consequences)\n",
    "x = torch.tensor([\n",
    "    [[1,1,1,1], [2,2,2,2], [3,3,3,3]],\n",
    "    [[10,10,10,10], [20,20,20,20], [30,30,30,30]]\n",
    "])\n",
    "print(f\"Size: {x.shape}\")\n",
    "print(f\"x: \\n{x}\\n\")\n",
    "\n",
    "a = x.view(x.size(1), -1)\n",
    "print(f\"\\nSize: {a.shape}\")\n",
    "print(f\"a: \\n{a}\\n\")\n",
    "\n",
    "b = x.transpose(0,1).contiguous()\n",
    "print(f\"\\nSize: {b.shape}\")\n",
    "print(f\"b: \\n{b}\\n\")\n",
    "\n",
    "c = b.view(b.size(0), -1)\n",
    "print(f\"\\nSize: {c.shape}\")\n",
    "print(f\"c: \\n{c}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6256753d",
   "metadata": {},
   "source": [
    "When we reshape a tensor, we need to be careful. Reshaping can change the order of the elements in the tensor, which can cause problems if we're not expecting it. In the code above, we first create a three-dimensional tensor `x`. Then, we reshape it into a tensor a with dimensions `(3, 8)`. This flattens the tensor, so that all the elements are in a single row.\n",
    "\n",
    "Next, we transpose the first two dimensions of `x` to get a tensor `b`. However, `b` is not contiguous, which means that its elements are not in a simple, ordered sequence in memory. This can cause issues later on.\n",
    "\n",
    "Finally, we reshape `b` into a tensor c with dimensions `(2, 12)` using the .view() method. This could also cause issues, since the elements of b are not contiguous.\n",
    "\n",
    "So, when we reshape tensors, we need to be careful and make sure we understand the order of the element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c6bf65ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values: \n",
      "tensor([[ 0.5797, -0.0599,  0.1816],\n",
      "        [-0.6797, -0.2567, -1.8189]])\n",
      "Values: \n",
      "tensor([-0.1000, -0.3166, -1.6373])\n",
      "Values: \n",
      "tensor([ 0.7013, -2.7553])\n"
     ]
    }
   ],
   "source": [
    "## Dimensional operations\n",
    "x = torch.randn(2, 3)\n",
    "print(f\"Values: \\n{x}\")\n",
    "y = torch.sum(x, dim=0) # add each row's value for every column\n",
    "print(f\"Values: \\n{y}\")\n",
    "z = torch.sum(x, dim=1) # add each columns's value for every row\n",
    "print(f\"Values: \\n{z}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328b475f",
   "metadata": {},
   "source": [
    "### Indexing \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "56e7820f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: \n",
      "tensor([[ 0.2111,  0.3372,  0.6638,  1.0397],\n",
      "        [ 1.8434,  0.6588, -0.2349, -0.0306],\n",
      "        [ 1.7462, -0.0722, -1.6794, -1.7010]])\n",
      "x[:1] : \n",
      "tensor([[0.2111, 0.3372, 0.6638, 1.0397]]) \n",
      "x[:1,1:3] \n",
      " tensor([[0.3372, 0.6638]]) \n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3,4)\n",
    "print (f\"x: \\n{x}\")\n",
    "print (f\"x[:1] : \\n{x[:1]} \") # select first row\n",
    "print (f\"x[:1,1:3] \\n {x[:1,1:3]} \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de7d1100",
   "metadata": {},
   "source": [
    "The second print statement displays a slice of the tensor `x` using indexing. Specifically, it uses the slice notation `x[:1]` to select the first row of the tensor.\n",
    "\n",
    "The syntax `x[:1, 1:3]` means \"select the first row (`:1`) and columns 1 to 2 (`1:3`) of the tensor `x`\". The resulting sub-tensor will have shape `(1, 2)`, since it has one row and two columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0a78af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "02ffa660b6f6d9be8cca427b74bc9cb87fea4b28c9e17012788bc534d238c364"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
